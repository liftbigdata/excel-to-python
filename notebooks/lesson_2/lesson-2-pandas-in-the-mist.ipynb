{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data to be used\n",
    "\n",
    "simple1_df = pd.read_csv('simple_data_cleansing_1.csv')\n",
    "simple2_df = pd.read_csv('simple_data_cleansing_2.csv')\n",
    "\n",
    "solo_df = pd.read_csv('solo_table.tsv', sep='\\t')\n",
    "\n",
    "concat_a_df = pd.read_csv('concat_table_a.tsv', sep='\\t')\n",
    "concat_b_df = pd.read_csv('concat_table_b.tsv', sep='\\t')\n",
    "concat_c_df = pd.read_csv('concat_table_c.tsv', sep='\\t')\n",
    "\n",
    "tx_df = pd.read_csv('tx_table.tsv', sep='\\t')\n",
    "shipment_df = pd.read_csv('shipment_table.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excel to Python Lesson 2: Pandas in the Mist\n",
    "\n",
    "Lesson 1 focused on getting your data loaded into Pandas. \n",
    "Now, we'll start manipulating that data into something useful.\n",
    "\n",
    "This lesson is meant to be introductory level and will act as a survey of things that are possible.\n",
    "Future lessons will get into the digital weeds.\n",
    "\n",
    "Lesson Topics:\n",
    "* Simple Data Cleansing\n",
    "    * Handling Nulls\n",
    "    * Handling Duplicates\n",
    "    * Handling Duplicates\n",
    "* Table Manipulations\n",
    "    * Splitting Fields\n",
    "    * Dropping Columns\n",
    "    * Aggregations\n",
    "* Combining Tables\n",
    "    * Concat/Append - Combining Data\n",
    "    * Merge - Database Style Joins\n",
    "* Excel Lyfe\n",
    "    * VLOOKUP\n",
    "    * Pivot Tables\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Data Cleansing\n",
    "\n",
    "### Handling Nulls\n",
    "`df.dropna() # drops if anything in the row is null`\n",
    "\n",
    "`df.dropna(how='all') # drops if the entire row is null`\n",
    "\n",
    "`df.dropna(axis=1, how='all') # drops columns where all data is null`\n",
    "\n",
    "`df.fillna(0, inplace=True)`\n",
    "`df.fillna({1: 'X', 2: 0}, inplace=True)`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the data we have\n",
    "simple1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will drop any rows that have any nulls\n",
    "simple1_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's remove only the row that had all nulls\n",
    "simple1_df.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what if a column was all nulls?\n",
    "simple2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's remove favorite_color as it's all nulls\n",
    "new_simple_df = simple2_df.dropna(axis=1, how='all')\n",
    "new_simple_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's drop that null row\n",
    "new_simple_df = new_simple_df.dropna(how='all')\n",
    "new_simple_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's replace the null bird values with wren\n",
    "new_simple_df.fillna('wren')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try again by specifying the column to replace\n",
    "new_simple_df.fillna({'favorite_bird':'wren'}, inplace=True)\n",
    "new_simple_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And do the same for the name\n",
    "new_simple_df.fillna({'name':'Anonymous User'}, inplace=True)\n",
    "new_simple_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Duplicates\n",
    "\n",
    "`df.drop_duplicates()  # drops the pure duplicates`\n",
    "\n",
    "`df.drop_duplicates(['col1', 'col2'], keep='last')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_simple_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_simple_df.drop_duplicates(['name'], keep='last')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Table Manipulations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solo_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start by splitting the customer_name field into a first_name and last_name\n",
    "solo_df[['first_name', 'last_name']] = solo_df['customer_name'].str.split(' ', expand=True)\n",
    "solo_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get rid of customer_name and transit_code\n",
    "solo_df.drop(['customer_name', 'transit_code'], axis=1, inplace=True)\n",
    "solo_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Order Total Amount by Quarter\n",
    "\n",
    "If this was SQL, we could do like this:\n",
    "\n",
    "```\n",
    "SELECT quarter, SUM(order_total_amt)\n",
    "FROM solo_df\n",
    "GROUP BY quarter;\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solo_df.groupby('quarter').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solo_df.groupby('quarter').order_total_amt.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solo_df.groupby('quarter').order_total_amt.agg(min_order='min', max_order='max', avg_order='mean', total_order='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solo_df.groupby(['last_name']).order_total_amt.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solo_df['running_total'] = solo_df.order_total_amt.cumsum()\n",
    "solo_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concat - Combining Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add more of the same data to the end of a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_a_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_b_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.concat([concat_a_df, concat_b_df], ignore_index=True)\n",
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_c_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What happens here?\n",
    "pd.concat([concat_a_df, concat_c_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How about now?\n",
    "pd.concat([concat_a_df, concat_c_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge - Database Style Joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shipment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's join the table together!\n",
    "tx_shipment_df = pd.merge(tx_df, shipment_df, on='transaction_id')\n",
    "tx_shipment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do we have all the data?\n",
    "print(len(tx_df))\n",
    "print(len(shipment_df))\n",
    "print(len(tx_shipment_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why does this matter? Let's sum up the order totals.\n",
    "print('Transaction Total:', tx_df.order_total_amt.sum())\n",
    "print('Transaction Shipment Total:', tx_shipment_df.order_total_amt.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to do an outer join\n",
    "tx_shipment_outer_df = pd.merge(tx_df, shipment_df, on='transaction_id', how='left')\n",
    "print(len(tx_shipment_outer_df))\n",
    "print('Transaction Shipment Outer Total:', tx_shipment_outer_df.order_total_amt.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_shipment_outer_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excel Lyfe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vlookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vlookup_tx_df = pd.read_excel('vlookup-example_raw.xlsx', sheet_name='transaction')\n",
    "vlookup_prod_df = pd.read_excel('vlookup-example_raw.xlsx', sheet_name='product_lookup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vlookup_tx_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vlookup_prod_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vlookup_df = pd.merge(vlookup_tx_df, vlookup_prod_df, how='inner', on='product_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vlookup_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivot Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(tx_df, \n",
    "               values='order_total_amt', \n",
    "               index=['quarter'], \n",
    "               columns=['customer_name'], \n",
    "               aggfunc=np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(tx_df, \n",
    "               values='order_total_amt', \n",
    "               index=['quarter', 'customer_name'], \n",
    "               aggfunc=np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}